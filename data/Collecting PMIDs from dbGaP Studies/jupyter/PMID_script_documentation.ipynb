{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Python Script to Scrape all the PMIDs from multiple XML files\n",
    "\n",
    "I'll be using this Journal to document how I go about creating the script. Including used Libraries, functions, etc. \n",
    "(The Python Script will include comments as well but this will be more in depth.) \n",
    "\n",
    "#### Starting Small\n",
    "\n",
    "Since I have the table of contents to the studies website, I can collect each link to the .xml files which contain the PMIDs and manipulate them through requests to the server. \n",
    "\n",
    "I first have to collect all links through file manipulation and then once I have those in a text file, organized in their respective order, I can make a direct request to that website and collect the HTML information to get the PMID.\n",
    "\n",
    "> **Script Steps**\n",
    "> - Read the original Table of Contents.XML file as input\n",
    "> - Collect all Links into their own text file\n",
    "> - Refactor \"ftp://ftp.ncbi.nlm.nih.gov/dbgap/studies/phs000001/phs000001.v3.p1/GapExchange_phs000001.v3.p1.xml\" to https:// using Notepad++\n",
    "> - Move all refactored links into a List Structure\n",
    "> - Create a request to each website as we go down the list\n",
    "> - Parse the XML link using BeautifulSoup Librarys XML parser\n",
    "> - Search for the specific \"pmid\" tag within the XML and add all integers to the new text file, making sure there are no dupes. \n",
    "> - There will also be an error check for if the website is not available\n",
    "\n",
    "#### Success!\n",
    "\n",
    "I managed to successfully create a script to download PMID numbers from xml link pages into a text file. The code should be available and documented on Github. \n",
    "\n",
    "*Only Issue* after only downloading PMID's with 10 links (The total links are over 3,000) I recieved over 18,500 PMIDS. Which of course is just too much. After adding a parameter for duplicates and using only 5 I was still astonished by how much there was (Over 2000!). So that will be the next issue I tackle. \n"
   ],
   "id": "50fa0aae25a87a73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7bae213749aa54f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
